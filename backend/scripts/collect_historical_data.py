#!/usr/bin/env python3
"""
Instagram Historical Data Collection Script (Enhanced)
éå»ã®æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ»æ—¥æ¬¡çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Usage:
    # å˜ä¸€ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®æŒ‡å®šæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿åé›†ï¼ˆæŠ•ç¨¿+æ—¥æ¬¡çµ±è¨ˆï¼‰
    python scripts/collect_historical_data.py --account 17841435735142253 --from 2025-01-01 --to 2025-07-01

    # å…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®æŒ‡å®šæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿åé›†
    python scripts/collect_historical_data.py --all-accounts --from 2025-01-01 --to 2025-07-01

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æœªå–å¾—æŠ•ç¨¿ã®ã¿åé›†
    python scripts/collect_historical_data.py --missing-metrics

    # æŠ•ç¨¿ã®ã¿åé›†ï¼ˆæ—¥æ¬¡çµ±è¨ˆãªã—ï¼‰
    python scripts/collect_historical_data.py --account 17841435735142253 --from 2025-01-01 --to 2025-07-01 --posts-only

    # æ—¥æ¬¡çµ±è¨ˆã®ã¿åé›†ï¼ˆæ–°æ©Ÿèƒ½ï¼‰
    python scripts/collect_historical_data.py --account 17841435735142253 --from 2025-01-01 --to 2025-07-01 --daily-stats-only
"""

import asyncio
import sys
import argparse
import logging
import os
from datetime import datetime, date, timedelta
from typing import Optional, List, Dict, Any
import json
from pathlib import Path
from dotenv import load_dotenv

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

from app.services.data_collection.historical_collector_service import create_historical_collector
from app.core.database import test_connection, get_db_sync
from app.repositories.instagram_account_repository import InstagramAccountRepository
from app.repositories.instagram_daily_stats_repository import InstagramDailyStatsRepository
from app.services.data_collection.instagram_api_client import InstagramAPIClient

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('historical_collection.log', mode='a')
    ]
)
logger = logging.getLogger(__name__)

def parse_arguments():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è§£æï¼ˆç°¡ç´ åŒ–ç‰ˆï¼‰"""
    parser = argparse.ArgumentParser(
        description='Instagram Historical Data Collection Script (Simplified)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # å˜ä¸€ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®æŒ‡å®šæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿åé›†
  python scripts/collect_historical_data.py --account 17841435735142253 --from 2025-01-01 --to 2025-07-01

  # å…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®æŒ‡å®šæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿åé›†
  python scripts/collect_historical_data.py --all-accounts --from 2025-01-01 --to 2025-07-01

  # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æœªå–å¾—æŠ•ç¨¿ã®ã¿åé›†
  python scripts/collect_historical_data.py --missing-metrics

  # å…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹æœªå–å¾—æŠ•ç¨¿ã®ã¿åé›†
  python scripts/collect_historical_data.py --all-accounts --missing-metrics
        """
    )
    
    # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæŒ‡å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆæ’ä»–çš„ï¼‰
    account_group = parser.add_mutually_exclusive_group(required=True)
    account_group.add_argument(
        '--account',
        type=str,
        help='Instagram User IDï¼ˆå˜ä¸€ã‚¢ã‚«ã‚¦ãƒ³ãƒˆï¼‰',
        metavar='USER_ID'
    )
    
    account_group.add_argument(
        '--all-accounts',
        action='store_true',
        help='å…¨ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’å¯¾è±¡ã«å®Ÿè¡Œ'
    )
    
    account_group.add_argument(
        '--missing-metrics',
        action='store_true',
        help='ãƒ¡ãƒˆãƒªã‚¯ã‚¹æœªå–å¾—æŠ•ç¨¿ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ã¿åé›†ï¼ˆå…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå¯¾è±¡ï¼‰'
    )
    
    # æœŸé–“æŒ‡å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆmissing-metricsã®å ´åˆã¯ä¸è¦ï¼‰
    parser.add_argument(
        '--from',
        dest='from_date',
        type=str,
        help='é–‹å§‹æ—¥ä»˜ (YYYY-MM-DDå½¢å¼)',
        metavar='YYYY-MM-DD'
    )
    
    parser.add_argument(
        '--to',
        dest='to_date',
        type=str,
        help='çµ‚äº†æ—¥ä»˜ (YYYY-MM-DDå½¢å¼)',
        metavar='YYYY-MM-DD'
    )
    
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='è©³ç´°ãƒ­ã‚°å‡ºåŠ›'
    )
    
    parser.add_argument(
        '-y', '--yes',
        action='store_true',
        help='ç¢ºèªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—'
    )
    
    # æ–°ã—ã„ã‚ªãƒ—ã‚·ãƒ§ãƒ³: åé›†ãƒ‡ãƒ¼ã‚¿ç¨®åˆ¥
    parser.add_argument(
        '--posts-only',
        action='store_true',
        help='æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã®ã¿åé›†ï¼ˆæ—¥æ¬¡çµ±è¨ˆã‚’ä½œæˆã—ãªã„ï¼‰'
    )
    
    parser.add_argument(
        '--daily-stats-only',
        action='store_true',
        help='æ—¥æ¬¡çµ±è¨ˆã®ã¿ä½œæˆï¼ˆæŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã¯æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é›†ç´„ï¼‰'
    )
    
    return parser.parse_args()

def validate_date(date_string: str) -> date:
    """æ—¥ä»˜æ–‡å­—åˆ—ã®æ¤œè¨¼"""
    try:
        return datetime.strptime(date_string, '%Y-%m-%d').date()
    except ValueError:
        raise argparse.ArgumentTypeError(f"ç„¡åŠ¹ãªæ—¥ä»˜å½¢å¼ã§ã™: {date_string}. YYYY-MM-DD å½¢å¼ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")

def validate_arguments(args):
    """å¼•æ•°ã®æ¤œè¨¼"""
    # missing-metricsä»¥å¤–ã®å ´åˆã¯æœŸé–“æŒ‡å®šãŒå¿…è¦
    if not args.missing_metrics:
        if not args.from_date or not args.to_date:
            raise ValueError("--from ã¨ --to ã®æ—¥ä»˜ãŒå¿…è¦ã§ã™ã€‚--missing-metrics ã‚’ä½¿ç”¨ã—ã¦ã„ãªã„å ´åˆã¯ã€--from ã¨ --to ã®æ—¥ä»˜ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
    
    # æ—¥ä»˜ã®æ¤œè¨¼
    if args.from_date:
        args.from_date = validate_date(args.from_date)
    if args.to_date:
        args.to_date = validate_date(args.to_date)
        
    # æ—¥ä»˜ã®é †åºç¢ºèª
    if args.from_date and args.to_date and args.from_date > args.to_date:
        raise ValueError("é–‹å§‹æ—¥ä»˜ã¯çµ‚äº†æ—¥ä»˜ã‚ˆã‚Šå‰ã‹ã€åŒã˜ã§ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚")

async def get_target_accounts(args) -> List[str]:
    """å¯¾è±¡ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
    if args.account:
        return [args.account]
    elif args.all_accounts or args.missing_metrics:
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å…¨ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’å–å¾—
        db = get_db_sync()
        repo = InstagramAccountRepository(db)
        accounts = await repo.get_active_accounts()
        return [str(account.instagram_user_id) for account in accounts]
    else:
        raise ValueError("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

def setup_logging(verbose: bool):
    """ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š"""
    if verbose:
        logging.getLogger().setLevel(logging.DEBUG)
        logging.getLogger('app').setLevel(logging.DEBUG)
        logger.info("è©³ç´°ãƒ­ã‚°å‡ºåŠ›ã‚’æœ‰åŠ¹ã«ã—ã¾ã—ãŸ")

def print_collection_plan(args, target_accounts: List[str]):
    """åé›†è¨ˆç”»ã®è¡¨ç¤º"""
    print("\n" + "="*60)
    print("ğŸ“Š éå»ãƒ‡ãƒ¼ã‚¿åé›†è¨ˆç”»")
    print("="*60)
    
    if len(target_accounts) == 1:
        print(f"ğŸ¯ ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ: {target_accounts[0]}")
    else:
        print(f"ğŸ¯ ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ: {len(target_accounts)} ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ")
        if len(target_accounts) <= 5:
            for i, account in enumerate(target_accounts, 1):
                print(f"   {i:2d}. {account}")
        else:
            for i, account in enumerate(target_accounts[:3], 1):
                print(f"   {i:2d}. {account}")
            print(f"   ... ãã—ã¦ {len(target_accounts) - 3} ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ")
    
    if args.missing_metrics:
        print(f"ğŸ“‹ ãƒ¢ãƒ¼ãƒ‰: ãƒ¡ãƒˆãƒªã‚¯ã‚¹æœªå–å¾—æŠ•ç¨¿ã®ã¿åé›†")
        print(f"ğŸ“… æœŸé–“: éå»30æ—¥é–“ï¼ˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ã¿ï¼‰")
    elif args.posts_only:
        print(f"ğŸ“‹ ãƒ¢ãƒ¼ãƒ‰: æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã®ã¿åé›†")
        print(f"ğŸ“… æœŸé–“: {args.from_date} ã‹ã‚‰ {args.to_date}")
        print(f"ğŸ”„ å‡¦ç†: æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ + ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†")
    elif args.daily_stats_only:
        print(f"ğŸ“‹ ãƒ¢ãƒ¼ãƒ‰: æ—¥æ¬¡çµ±è¨ˆã®ã¿ä½œæˆ")
        print(f"ğŸ“… æœŸé–“: {args.from_date} ã‹ã‚‰ {args.to_date}")
        print(f"ğŸ”„ å‡¦ç†: æ—¢å­˜æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ—¥æ¬¡çµ±è¨ˆã‚’é›†ç´„")
    else:
        print(f"ğŸ“‹ ãƒ¢ãƒ¼ãƒ‰: å®Œå…¨ãƒ‡ãƒ¼ã‚¿åé›†ï¼ˆæŠ•ç¨¿ + æ—¥æ¬¡çµ±è¨ˆï¼‰")
        print(f"ğŸ“… æœŸé–“: {args.from_date} ã‹ã‚‰ {args.to_date}")
        print(f"ğŸ”„ å‡¦ç†: æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿åé›† â†’ ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾— â†’ æ—¥æ¬¡çµ±è¨ˆä½œæˆ")
    
    print("="*60)

def generate_output_filename(operation_type: str, account_info: str = None) -> str:
    """å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    if operation_type == "missing_metrics":
        filename = f"missing_etrics_collection_{timestamp}.json"
    elif operation_type == "single_account":
        filename = f"single_account_collection_{account_info}_{timestamp}.json"
    elif operation_type == "all_accounts":
        filename = f"all_accounts_collection_{timestamp}.json"
    else:
        filename = f"historical_collection_{timestamp}.json"
    
    return filename

def save_collection_result(result_data: Dict[str, Any], filename: str):
    """åé›†çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    output_dir = Path(__file__).parent / "output"
    output_dir.mkdir(exist_ok=True)
    
    output_path = output_dir / filename
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result_data, f, indent=2, ensure_ascii=False, default=str)
    
    logger.info(f"çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")
    print(f"ğŸ“ çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")

def format_single_result(result, operation_type: str, execution_time: float) -> Dict[str, Any]:
    """å˜ä¸€ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®çµæœã‚’æ•´å½¢"""
    # æ—¥æ¬¡çµ±è¨ˆçµæœã®å ´åˆï¼ˆdictå½¢å¼ï¼‰
    if isinstance(result, dict):
        return {
            "metadata": {
                "operation_type": operation_type,
                "execution_timestamp": datetime.now().isoformat(),
                "execution_time_seconds": round(execution_time, 2),
                "script_version": "2.0-enhanced"
            },
            "account_info": {
                "account_id": result.get('account_id'),
                "instagram_user_id": result.get('account_id')
            },
            "collection_config": {
                "collection_type": "daily_stats_aggregation",
                "date_range": {
                    "start_date": result.get('start_date').isoformat() if result.get('start_date') else None,
                    "end_date": result.get('end_date').isoformat() if result.get('end_date') else None
                }
            },
            "execution_results": {
                "total_days": result.get('total_days', 0),
                "processed_days": result.get('processed_days', 0),
                "success_days": result.get('success_days', 0),
                "failed_days": result.get('failed_days', 0),
                "success_rate_percent": round(result.get('success_days', 0) / result.get('total_days', 1) * 100, 1) if result.get('total_days', 0) > 0 else 0
            },
            "status": {
                "completed_successfully": result.get('error_message') is None,
                "error_message": result.get('error_message')
            },
            "collected_data": {
                "current_account_data": result.get('current_account_data', {}),
                "daily_stats": result.get('daily_stats', [])
            }
        }
    
    # å¾“æ¥ã®æŠ•ç¨¿åé›†çµæœã®å ´åˆï¼ˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå½¢å¼ï¼‰
    else:
        return {
            "metadata": {
                "operation_type": operation_type,
                "execution_timestamp": datetime.now().isoformat(),
                "execution_time_seconds": round(execution_time, 2),
                "script_version": "2.0-enhanced"
            },
            "account_info": {
                "account_id": result.account_id,
                "instagram_user_id": result.instagram_user_id
            },
            "collection_config": {
                "collection_type": result.collection_type,
                "date_range": {
                    "start_date": result.start_date.isoformat() if result.start_date else None,
                    "end_date": result.end_date.isoformat() if result.end_date else None
                }
            },
            "execution_results": {
                "total_items": result.total_items,
                "processed_items": result.processed_items,
                "success_items": result.success_items,
                "failed_items": result.failed_items,
                "success_rate_percent": round(result.success_items / result.total_items * 100, 1) if result.total_items > 0 else 0
            },
            "timing": {
                "started_at": result.started_at.isoformat(),
                "completed_at": result.completed_at.isoformat() if result.completed_at else None,
                "duration_seconds": result.duration_seconds
            },
            "status": {
                "completed_successfully": result.error_message is None,
                "error_message": result.error_message
            },
            "additional_data": getattr(result, 'additional_data', None)
        }

def format_bulk_results(all_results: List, target_accounts: List[str], operation_type: str, execution_time: float) -> Dict[str, Any]:
    """è¤‡æ•°ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®çµæœã‚’æ•´å½¢"""
    successful_accounts = len([r for r in all_results if r and r.error_message is None])
    failed_accounts = len(target_accounts) - successful_accounts
    
    total_items = sum(r.total_items for r in all_results if r)
    total_success = sum(r.success_items for r in all_results if r)
    total_failed = sum(r.failed_items for r in all_results if r)
    
    return {
        "metadata": {
            "operation_type": operation_type,
            "execution_timestamp": datetime.now().isoformat(),
            "execution_time_seconds": round(execution_time, 2),
            "script_version": "2.0-simplified"
        },
        "summary": {
            "total_accounts": len(target_accounts),
            "successful_accounts": successful_accounts,
            "failed_accounts": failed_accounts,
            "account_success_rate_percent": round(successful_accounts / len(target_accounts) * 100, 1) if target_accounts else 0,
            "total_data_items": total_items,
            "successful_data_items": total_success,
            "failed_data_items": total_failed,
            "data_success_rate_percent": round(total_success / total_items * 100, 1) if total_items > 0 else 0
        },
        "account_results": [
            {
                "account_id": result.account_id,
                "instagram_user_id": result.instagram_user_id,
                "success": result.error_message is None,
                "total_items": result.total_items,
                "success_items": result.success_items,
                "failed_items": result.failed_items,
                "duration_seconds": result.duration_seconds,
                "error_message": result.error_message
            }
            for result in all_results if result
        ],
        "failed_accounts": [
            account_id for account_id in target_accounts 
            if not any(r and r.account_id == account_id for r in all_results)
        ]
    }

def print_result_summary(result_data: Dict[str, Any]):
    """çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
    print("\n" + "="*60)
    print("ğŸ“Š COLLECTION RESULTS SUMMARY")
    print("="*60)
    
    if "summary" in result_data:
        # è¤‡æ•°ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®å ´åˆ
        summary = result_data["summary"]
        print(f"ğŸ¯ å¯¾è±¡ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ: {summary['total_accounts']}")
        print(f"âœ… æˆåŠŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆ: {summary['successful_accounts']}")
        print(f"âŒ å¤±æ•—ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ: {summary['failed_accounts']}")
        print(f"ğŸ“ˆ ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæˆåŠŸç‡: {summary['account_success_rate_percent']}%")
        print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {summary['total_data_items']}")
        print(f"ğŸ‰ æˆåŠŸãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {summary['successful_data_items']}")
        print(f"ğŸ’¥ å¤±æ•—ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {summary['failed_data_items']}")
        print(f"ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿æˆåŠŸç‡: {summary['data_success_rate_percent']}%")
    else:
        # å˜ä¸€ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®å ´åˆ
        results = result_data["execution_results"]
        print(f"ğŸ¯ å¯¾è±¡ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ: {result_data['account_info']['instagram_user_id']}")
        
        # æ—¥æ¬¡çµ±è¨ˆã®å ´åˆã¨ãã®ä»–ã®å ´åˆã§è¡¨ç¤ºã‚’åˆ†ã‘ã‚‹
        if "total_days" in results:
            # æ—¥æ¬¡çµ±è¨ˆã®å ´åˆ
            print(f"ğŸ“… å¯¾è±¡æ—¥æ•°: {results['total_days']}")
            print(f"âœ… æˆåŠŸæ—¥æ•°: {results['success_days']}")
            print(f"âŒ å¤±æ•—æ—¥æ•°: {results['failed_days']}")
            print(f"ğŸ“ˆ æˆåŠŸç‡: {results['success_rate_percent']}%")
            
            # ç¾åœ¨ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
            if "collected_data" in result_data and result_data["collected_data"]["current_account_data"]:
                current_data = result_data["collected_data"]["current_account_data"]
                print(f"ğŸ‘¥ ç¾åœ¨ã®ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°: {current_data.get('followers_count', 'N/A')}")
                print(f"ğŸ“ ç·æŠ•ç¨¿æ•°: {current_data.get('media_count', 'N/A')}")
            
            # æ—¥æ¬¡çµ±è¨ˆã‚µãƒãƒªãƒ¼
            daily_stats = result_data["collected_data"]["daily_stats"]
            if daily_stats:
                total_posts = sum(stat['posts_count'] for stat in daily_stats)
                total_likes = sum(stat['total_likes'] for stat in daily_stats)
                total_comments = sum(stat['total_comments'] for stat in daily_stats)
                print(f"ğŸ“Š æœŸé–“å†…æŠ•ç¨¿æ•°: {total_posts}")
                print(f"ğŸ‘ æœŸé–“å†…ã„ã„ã­æ•°: {total_likes}")
                print(f"ğŸ’¬ æœŸé–“å†…ã‚³ãƒ¡ãƒ³ãƒˆæ•°: {total_comments}")
        else:
            # å¾“æ¥ã®æŠ•ç¨¿åé›†ã®å ´åˆ
            print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {results['total_items']}")
            print(f"âœ… æˆåŠŸãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {results['success_items']}")
            print(f"âŒ å¤±æ•—ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {results['failed_items']}")
            print(f"ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿æˆåŠŸç‡: {results['success_rate_percent']}%")
            
            if "timing" in result_data:
                print(f"â±ï¸ å®Ÿè¡Œæ™‚é–“: {result_data['timing']['duration_seconds']}s")
    
    print(f"â±ï¸ åˆè¨ˆå®Ÿè¡Œæ™‚é–“: {result_data['metadata']['execution_time_seconds']}s")
    print("="*60)

async def collect_daily_stats_from_posts(
    account_id: str, 
    start_date: date, 
    end_date: date
) -> Dict[str, Any]:
    """æ—¢å­˜ã®æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ—¥æ¬¡çµ±è¨ˆã‚’ä½œæˆ"""
    logger.info(f"ğŸ“Š æ—¥æ¬¡çµ±è¨ˆä½œæˆé–‹å§‹: {account_id} ({start_date} ã‹ã‚‰ {end_date})")
    
    result = {
        'account_id': account_id,
        'start_date': start_date,
        'end_date': end_date,
        'total_days': 0,
        'processed_days': 0,
        'success_days': 0,
        'failed_days': 0,
        'current_account_data': {},
        'daily_stats': []
    }
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
        db = get_db_sync()
        account_repo = InstagramAccountRepository(db)
        daily_stats_repo = InstagramDailyStatsRepository(db)
        
        # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå–å¾—
        account = await account_repo.get_by_instagram_user_id(account_id)
        if not account:
            raise ValueError(f"Account not found: {account_id}")
        
        # ç¾åœ¨ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆåŸºæœ¬æƒ…å ±ï¼‰
        async with InstagramAPIClient() as api_client:
            try:
                current_basic_data = await api_client.get_basic_account_data(
                    account.instagram_user_id,
                    account.access_token_encrypted
                )
                result['current_account_data'] = current_basic_data
                logger.info(f"ç¾åœ¨ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿: followers={current_basic_data.get('followers_count')}, posts={current_basic_data.get('media_count')}")
            except Exception as e:
                logger.warning(f"åŸºæœ¬ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {e}")
                current_basic_data = {}
        
        # å…¨æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿å–å¾—
        async with InstagramAPIClient() as api_client:
            logger.info("å…¨æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
            url = api_client.config.get_user_media_url(account.instagram_user_id)
            all_posts = []
            next_url = None
            page_count = 0
            
            while True:
                page_count += 1
                params = {
                    'fields': 'id,media_type,permalink,caption,timestamp,like_count,comments_count',
                    'access_token': account.access_token_encrypted,
                    'limit': 100
                }
                
                try:
                    if next_url:
                        response = await api_client._make_request(next_url, {})
                    else:
                        response = await api_client._make_request(url, params)
                    
                    posts = response.get('data', [])
                    all_posts.extend(posts)
                    
                    logger.debug(f"Page {page_count}: {len(posts)} posts retrieved")
                    
                    paging = response.get('paging', {})
                    next_url = paging.get('next')
                    
                    if not next_url:
                        break
                    
                    await asyncio.sleep(1)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œ
                    
                except Exception as e:
                    logger.error(f"æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼ (page {page_count}): {e}")
                    break
            
            logger.info(f"å–å¾—å®Œäº†: {len(all_posts)} ä»¶ã®æŠ•ç¨¿")
        
        # æ—¥ä»˜ã”ã¨ã«æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã‚’é›†ç´„
        current_date = start_date
        while current_date <= end_date:
            result['total_days'] += 1
            result['processed_days'] += 1
            
            try:
                # ãã®æ—¥ã®æŠ•ç¨¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                daily_posts = []
                for post in all_posts:
                    timestamp = post.get('timestamp', '')
                    if timestamp:
                        try:
                            post_date_str = timestamp.split('T')[0]
                            post_date = date.fromisoformat(post_date_str)
                            if post_date == current_date:
                                daily_posts.append(post)
                        except:
                            continue
                
                # æ—¥æ¬¡çµ±è¨ˆè¨ˆç®—
                posts_count = len(daily_posts)
                total_likes = sum(p.get('like_count', 0) for p in daily_posts)
                total_comments = sum(p.get('comments_count', 0) for p in daily_posts)
                
                # ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—åˆ†å¸ƒ
                media_types = {}
                for post in daily_posts:
                    media_type = post.get('media_type', 'UNKNOWN')
                    media_types[media_type] = media_types.get(media_type, 0) + 1
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
                stats_data = {
                    'account_id': account.id,
                    'stats_date': current_date,
                    'followers_count': current_basic_data.get('followers_count', 0),  # ç¾åœ¨å€¤
                    'following_count': current_basic_data.get('follows_count', 0),    # ç¾åœ¨å€¤
                    'media_count': current_basic_data.get('media_count', 0),          # ç¾åœ¨å€¤
                    'posts_count': posts_count,
                    'total_likes': total_likes,
                    'total_comments': total_comments,
                    'media_type_distribution': json.dumps(media_types),
                    'data_sources': json.dumps(['posts_aggregation'])
                }
                
                # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯ã—ã¦ä½œæˆã¾ãŸã¯æ›´æ–°
                existing_stats = await daily_stats_repo.get_by_specific_date(account.id, current_date)
                
                if existing_stats:
                    # æ›´æ–°
                    updated_stats = await daily_stats_repo.update(existing_stats.id, stats_data)
                    logger.debug(f"âœ… æ›´æ–°: {current_date} - {posts_count}æŠ•ç¨¿, {total_likes}ã„ã„ã­, {total_comments}ã‚³ãƒ¡ãƒ³ãƒˆ")
                else:
                    # æ–°è¦ä½œæˆ
                    new_stats = await daily_stats_repo.create(stats_data)
                    logger.debug(f"âœ… æ–°è¦: {current_date} - {posts_count}æŠ•ç¨¿, {total_likes}ã„ã„ã­, {total_comments}ã‚³ãƒ¡ãƒ³ãƒˆ")
                
                result['success_days'] += 1
                result['daily_stats'].append({
                    'date': current_date.isoformat(),
                    'posts_count': posts_count,
                    'total_likes': total_likes,
                    'total_comments': total_comments,
                    'media_types': media_types
                })
                
            except Exception as e:
                logger.error(f"âŒ æ—¥æ¬¡çµ±è¨ˆä½œæˆå¤±æ•—: {current_date} - {str(e)}")
                result['failed_days'] += 1
            
            current_date += timedelta(days=1)
        
        logger.info(f"âœ… æ—¥æ¬¡çµ±è¨ˆä½œæˆå®Œäº†: {result['success_days']}/{result['total_days']} æ—¥")
        return result
        
    except Exception as e:
        logger.error(f"âŒ æ—¥æ¬¡çµ±è¨ˆä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        result['error_message'] = str(e)
        return result

async def collect_single_account(account_id: str, args) -> Optional[any]:
    """å˜ä¸€ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ãƒ‡ãƒ¼ã‚¿åé›†"""
    logger.info(f"ğŸš€ ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ: {account_id} ã®ãƒ‡ãƒ¼ã‚¿åé›†ã‚’é–‹å§‹ã—ã¾ã™")
    
    try:
        if args.daily_stats_only:
            # æ—¥æ¬¡çµ±è¨ˆã®ã¿ä½œæˆ
            result = await collect_daily_stats_from_posts(
                account_id=account_id,
                start_date=args.from_date,
                end_date=args.to_date
            )
            return result
        
        else:
            # å¾“æ¥ã®æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿åé›†
            collector = create_historical_collector()
            
            if args.missing_metrics:
                result = await collector.collect_missing_metrics(
                    account_id=account_id,
                    days_back=30
                )
            else:
                include_metrics = not args.posts_only
                result = await collector.collect_historical_posts(
                    account_id=account_id,
                    start_date=args.from_date,
                    end_date=args.to_date,
                    include_metrics=include_metrics,
                    chunk_size=50
                )
            
            # æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿åé›†å¾Œã€æ—¥æ¬¡çµ±è¨ˆã‚‚ä½œæˆï¼ˆposts-onlyã§ãªã„å ´åˆï¼‰
            if not args.posts_only and not args.missing_metrics:
                logger.info("æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†ã€‚æ—¥æ¬¡çµ±è¨ˆã‚’ä½œæˆä¸­...")
                daily_stats_result = await collect_daily_stats_from_posts(
                    account_id=account_id,
                    start_date=args.from_date,
                    end_date=args.to_date
                )
                
                # çµæœã‚’ãƒãƒ¼ã‚¸
                result.additional_data = daily_stats_result
            
            logger.info(f"âœ… ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ: {account_id} ã®ãƒ‡ãƒ¼ã‚¿åé›†ãŒå®Œäº†ã—ã¾ã—ãŸ: {result.success_items}/{result.total_items} ä»¶")
            return result
        
    except Exception as e:
        logger.error(f"âŒ ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ: {account_id} ã®ãƒ‡ãƒ¼ã‚¿åé›†ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return None

async def collect_multiple_accounts(target_accounts: List[str], args) -> List:
    """è¤‡æ•°ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®é †æ¬¡ãƒ‡ãƒ¼ã‚¿åé›†"""
    logger.info(f"ğŸ {len(target_accounts)} ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ãƒ‡ãƒ¼ã‚¿åé›†ã‚’é–‹å§‹ã—ã¾ã™")
    
    all_results = []
    
    for i, account_id in enumerate(target_accounts, 1):
        logger.info(f"ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ: {i}/{len(target_accounts)}: {account_id} ã®ãƒ‡ãƒ¼ã‚¿åé›†ã‚’é–‹å§‹ã—ã¾ã™")
        
        try:
            result = await collect_single_account(account_id, args)
            if result:
                all_results.append(result)
            
            # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé–“ã®å¾…æ©Ÿï¼ˆæœ€å¾Œä»¥å¤–ï¼‰
            if i < len(target_accounts):
                logger.info("â±ï¸ æ¬¡ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¸ã®ç§»è¡Œã‚’10ç§’å¾…ã¡ã¾ã™...")
                await asyncio.sleep(10)
                
        except Exception as e:
            logger.error(f"ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ: {account_id} ã®ãƒ‡ãƒ¼ã‚¿åé›†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    
    return all_results

async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    start_time = datetime.now()
    
    try:
        args = parse_arguments()
        
        # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
        setup_logging(args.verbose)
        
        # å¼•æ•°æ¤œè¨¼
        validate_arguments(args)
        
        logger.info("Instagram éå»ãƒ‡ãƒ¼ã‚¿åé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’é–‹å§‹ã—ã¾ã™")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ
        logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™...")
        if not test_connection():
            logger.error("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ")
            return 1
        logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã«æˆåŠŸã—ã¾ã—ãŸ")
        
        # å¯¾è±¡ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå–å¾—
        target_accounts = await get_target_accounts(args)
        logger.info(f"å¯¾è±¡ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ: {len(target_accounts)} ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ")
        
        # åé›†è¨ˆç”»è¡¨ç¤º
        print_collection_plan(args, target_accounts)
        
        # ç¢ºèªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        if not args.yes:
            response = input("\néå»ãƒ‡ãƒ¼ã‚¿åé›†ã‚’ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ")
            if response.lower() != 'y':
                print("åé›†ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚")
                return 0
        
        # ãƒ‡ãƒ¼ã‚¿åé›†å®Ÿè¡Œ
        if len(target_accounts) == 1:
            # å˜ä¸€ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå‡¦ç†
            result = await collect_single_account(target_accounts[0], args)
            
            if result:
                execution_time = (datetime.now() - start_time).total_seconds()
                
                # çµæœæ•´å½¢
                if args.missing_metrics:
                    operation_type = "missing_metrics_single"
                else:
                    operation_type = "single_account"
                
                result_data = format_single_result(result, operation_type, execution_time)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆãƒ»ä¿å­˜
                filename = generate_output_filename(operation_type, target_accounts[0])
                save_collection_result(result_data, filename)
                
                # çµæœè¡¨ç¤º
                print_result_summary(result_data)
                
                # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯: dictå½¢å¼ã¨ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå½¢å¼ã®ä¸¡æ–¹ã«å¯¾å¿œ
                if isinstance(result, dict):
                    return 0 if result.get('error_message') is None else 1
                else:
                    return 0 if result.error_message is None else 1
            else:
                logger.error("åé›†ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return 1
        
        else:
            # è¤‡æ•°ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå‡¦ç†
            all_results = await collect_multiple_accounts(target_accounts, args)
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            # çµæœæ•´å½¢
            if args.missing_metrics:
                operation_type = "missing_metrics_all"
            else:
                operation_type = "all_accounts"
            
            result_data = format_bulk_results(all_results, target_accounts, operation_type, execution_time)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆãƒ»ä¿å­˜
            filename = generate_output_filename(operation_type)
            save_collection_result(result_data, filename)
            
            # çµæœè¡¨ç¤º
            print_result_summary(result_data)
            
            # å¤±æ•—ã—ãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒã‚ã‚‹å ´åˆã¯ exit code 1
            failed_accounts = len(target_accounts) - len(all_results)
            return 1 if failed_accounts > 0 else 0
        
    except KeyboardInterrupt:
        logger.info("åé›†ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã—ã¾ã—ãŸ")
        return 130
    except Exception as e:
        logger.error(f"éå»ãƒ‡ãƒ¼ã‚¿åé›†ã«è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", exc_info=True)
        return 1

def cli_entry_point():
    """CLI ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        exit_code = asyncio.run(main())
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\nâš ï¸ åé›†ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã—ã¾ã—ãŸ")
        sys.exit(130)
    except Exception as e:
        print(f"\nğŸ’¥ è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    cli_entry_point()
